# Feature Specification: Remove Phantom Evidence Paths from ScoringMapper

**Feature Branch**: `002-scoringmapper-generate-evidence`
**Created**: 2025-09-28
**Status**: Draft
**Input**: User description: "- ScoringMapper._generate_evidence_paths() ä¼šå…ˆæšä¸¾ checklist item çš„çœŸå®è¯æ®æ–‡ä»¶ï¼ˆè¿™äº›ç¨åç”± EvidenceTracker å†™å‡ºï¼‰ï¼Œä½†å‡½æ•°ç»“å°¾è¿˜ç¡¬ç¼–ç äº† evaluation_summary.jsonã€category_breakdowns.jsonã€warnings.log ä¸‰ä¸ªé”®ã€‚
  - å½“å‰ç‰ˆæœ¬çš„æµæ°´çº¿å¹¶ä¸ä¼šç”Ÿæˆè¿™äº›"æ±‡æ€»"æ–‡ä»¶ï¼ŒEvidenceTracker.save_evidence_files() å’Œ update_evidence_paths_with_generated_files() éƒ½ä¸ä¼šè¡¥ä¸Šã€‚
  - ç»“æœï¼šscore_input.json.evidence_paths å‘å¤–æš´éœ²äº†å¹¶ä¸å­˜åœ¨çš„è·¯å¾„ï¼Œé›†æˆæ–¹ä¼šæŒ‰å›¾ç´¢éª¥å´æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œæ–‡æ¡£/æ¥å£ä¸çœŸå®äº§ç‰©ä¸ä¸€è‡´ã€‚

  ä»»åŠ¡ç›®æ ‡

  å½»åº•ç§»é™¤è¿™äº›è™šæ„å ä½ç¬¦ï¼Œè®© evidence_paths åªåŒ…å«çœŸå®å­˜åœ¨çš„è¯æ®æ–‡ä»¶ã€‚å®Œæˆåï¼š

  - è¿è¡Œ CLI / smoke æµæ°´çº¿æ—¶ï¼Œscore_input.json.evidence_paths ä¸å†å‡ºç° evaluation_summaryã€category_breakdownsã€warnings_log ç­‰é”®ã€‚
  - ç›¸å…³ä»£ç ã€æ–‡æ¡£ã€å•æµ‹ä¸è¿™ä¸€è¡Œä¸ºä¿æŒä¸€è‡´ã€‚"

## Execution Flow (main)
```
1. Parse user description from Input
   â†’ Feature targets evidence path consistency in evaluation pipeline
2. Extract key concepts from description
   â†’ Actors: code-score tool users, integrating systems
   â†’ Actions: generate score_input.json, reference evidence files
   â†’ Data: evidence_paths field in JSON output
   â†’ Constraints: paths must point to files that actually exist
3. For each unclear aspect:
   â†’ Clear problem definition provided
4. Fill User Scenarios & Testing section
   â†’ User flow: run evaluation pipeline, consume evidence paths
5. Generate Functional Requirements
   â†’ Each requirement targets actual file existence
6. Identify Key Entities (if data involved)
   â†’ score_input.json structure and evidence file system
7. Run Review Checklist
   â†’ No clarifications needed, implementation boundaries clear
8. Return: SUCCESS (spec ready for planning)
```

---

## âš¡ Quick Guidelines
- âœ… Focus on WHAT users need and WHY
- âŒ Avoid HOW to implement (no tech stack, APIs, code structure)
- ğŸ‘¥ Written for business stakeholders, not developers

---

## User Scenarios & Testing *(mandatory)*

### Primary User Story
When users run the code-score evaluation pipeline and receive a score_input.json file, all file paths listed in the evidence_paths field must point to files that actually exist on the filesystem. Integrating systems should be able to reliably access every referenced evidence file for additional processing or verification.

### Acceptance Scenarios
1. **Given** a repository evaluation has completed, **When** a user examines score_input.json, **Then** every path in evidence_paths field corresponds to an existing file
2. **Given** an integration system processes score_input.json, **When** it attempts to read files from evidence_paths, **Then** all file access operations succeed without file-not-found errors
3. **Given** the evaluation pipeline runs end-to-end, **When** evidence_paths is generated, **Then** it contains only paths for files actually written by the evidence tracking system

### Edge Cases
- What happens when evidence generation partially fails but some files are created?
- How does the system handle permission issues preventing evidence file creation?
- What occurs if disk space runs out during evidence file writing?

## Requirements *(mandatory)*

### Functional Requirements
- **FR-001**: System MUST ensure all paths in score_input.json evidence_paths field point to existing files
- **FR-002**: System MUST exclude non-existent placeholder files from evidence_paths output
- **FR-003**: Users MUST be able to access every file referenced in evidence_paths without encountering file-not-found errors
- **FR-004**: System MUST maintain consistency between evidence file generation and path reporting
- **FR-005**: System MUST validate evidence file existence before including paths in final output

### Key Entities *(include if feature involves data)*
- **score_input.json**: JSON output file containing evaluation results and evidence_paths field that lists available evidence files
- **Evidence Files**: Individual files containing detailed evaluation evidence, organized by checklist item and category
- **Evidence Paths Mapping**: Dictionary structure within score_input.json that maps logical evidence categories to actual file system paths

---

## Review & Acceptance Checklist
*GATE: Automated checks run during main() execution*

### Content Quality
- [x] No implementation details (languages, frameworks, APIs)
- [x] Focused on user value and business needs
- [x] Written for non-technical stakeholders
- [x] All mandatory sections completed

### Requirement Completeness
- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Requirements are testable and unambiguous
- [x] Success criteria are measurable
- [x] Scope is clearly bounded
- [x] Dependencies and assumptions identified

---

## Execution Status
*Updated by main() during processing*

- [x] User description parsed
- [x] Key concepts extracted
- [x] Ambiguities marked
- [x] User scenarios defined
- [x] Requirements generated
- [x] Entities identified
- [x] Review checklist passed

---
