"""
Standalone CLI command for LLM report generation.

This module provides the `llm-report` command interface for generating
human-readable evaluation reports from score_input.json files.
"""

import sys
import click
import logging
from pathlib import Path
from typing import Optional

from ..llm.report_generator import ReportGenerator, ReportGeneratorError, LLMProviderError
from ..llm.template_loader import TemplateLoaderError


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)


@click.command(name='llm-report')
@click.argument('score_input_path', type=click.Path(exists=True, dir_okay=False))
@click.option('--prompt', '--template',
              type=click.Path(exists=True, dir_okay=False),
              help='Path to custom prompt template file (default: specs/prompts/llm_report.md)')
@click.option('--output', '-o',
              type=click.Path(dir_okay=False),
              default='output/final_report.md',
              help='Output path for generated report (default: output/final_report.md)')
@click.option('--provider',
              type=click.Choice(['gemini', 'openai', 'claude'], case_sensitive=False),
              default='gemini',
              help='LLM provider to use for generation (default: gemini)')
@click.option('--verbose', '-v',
              is_flag=True,
              help='Enable detailed logging and progress information')
@click.option('--timeout',
              type=int,
              help='Override default timeout for LLM calls (seconds)')
@click.option('--validate-only',
              is_flag=True,
              help='Validate inputs and prerequisites without generating report')
def main(score_input_path: str,
         prompt: Optional[str],
         output: str,
         provider: str,
         verbose: bool,
         timeout: Optional[int],
         validate_only: bool):
    """
    Generate human-readable evaluation reports from code quality analysis data.

    Takes a score_input.json file from the checklist evaluation pipeline
    and generates a comprehensive, human-readable report using external LLM services.

    \b
    SCORE_INPUT_PATH: Path to score_input.json file from evaluation pipeline

    \b
    Examples:
      # Generate report with default settings
      uv run python -m src.cli.llm_report output/score_input.json

      # Use custom template and output location
      uv run python -m src.cli.llm_report output/score_input.json \\
        --prompt custom_template.md --output evaluation_report.md

      # Use different LLM provider
      uv run python -m src.cli.llm_report output/score_input.json \\
        --provider openai --timeout 60
    """
    try:
        # Validate argument combinations
        if validate_only and (timeout or prompt):
            logger.warning("‚ö†Ô∏è  Additional options ignored in validate-only mode")

        if timeout and timeout < 10:
            logger.error("‚ùå Timeout must be at least 10 seconds")
            sys.exit(2)

        if timeout and timeout > 300:
            logger.warning("‚ö†Ô∏è  Timeout over 5 minutes may cause issues")

        # Configure logging based on verbose flag
        if verbose:
            logging.getLogger().setLevel(logging.DEBUG)
            logger.debug("Verbose logging enabled")

        # Initialize report generator
        logger.info("ü§ñ Code Score LLM Report Generator")
        logger.info(f"üìä Processing: {score_input_path}")

        generator = ReportGenerator()

        # Handle validation-only mode
        if validate_only:
            return _handle_validation_only(generator, provider, prompt)

        # Validate prerequisites
        validation_result = generator.validate_prerequisites(provider)
        if not validation_result['valid']:
            logger.error("‚ùå Prerequisites validation failed:")
            for issue in validation_result['issues']:
                logger.error(f"   ‚Ä¢ {issue}")

            _print_setup_help(provider)
            sys.exit(2)

        logger.info("‚úÖ Prerequisites validated")

        # Generate report
        logger.info(f"üöÄ Generating report using {provider}")

        result = generator.generate_report(
            score_input_path=score_input_path,
            output_path=output,
            template_path=prompt,
            provider=provider,
            verbose=verbose,
            timeout=timeout
        )

        # Handle results
        _handle_generation_output(result, verbose)

        sys.exit(0)

    except ReportGeneratorError as e:
        logger.error(f"‚ùå Report generation failed: {e}")
        logger.info("üí° Try using --validate-only to check prerequisites")
        sys.exit(3)
    except LLMProviderError as e:
        logger.error(f"‚ùå LLM provider error: {e}")
        logger.info("üí° Check your LLM provider configuration and credentials")
        _print_provider_help(provider)
        sys.exit(4)
    except TemplateLoaderError as e:
        logger.error(f"‚ùå Template error: {e}")
        logger.info("üí° Check template syntax or use default template")
        if prompt:
            logger.info(f"üí° Problematic template: {prompt}")
        sys.exit(5)
    except FileNotFoundError as e:
        logger.error(f"‚ùå File not found: {e}")
        logger.info("üí° Ensure score_input.json exists from prior analysis")
        logger.info("üí° Run: uv run python -m src.cli.main <repo_url> --enable-checklist")
        sys.exit(1)
    except PermissionError as e:
        logger.error(f"‚ùå Permission denied: {e}")
        logger.info("üí° Check file permissions and output directory access")
        sys.exit(6)
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è  Generation interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {e}")
        logger.info("üí° Use --verbose for detailed error information")
        logger.info("üí° Use --validate-only to check system configuration")
        if verbose:
            import traceback
            traceback.print_exc()
        sys.exit(99)


def _handle_validation_only(generator: ReportGenerator,
                           provider: str,
                           template_path: Optional[str]) -> None:
    """Handle validation-only mode."""
    logger.info("üîç Validating prerequisites and configuration...")

    # Validate provider
    validation_result = generator.validate_prerequisites(provider)

    logger.info(f"\nüìã Validation Results:")
    logger.info(f"   Provider ({provider}): {'‚úÖ' if validation_result['provider_available'] else '‚ùå'}")
    logger.info(f"   Environment: {'‚úÖ' if validation_result['environment_valid'] else '‚ùå'}")
    logger.info(f"   Template: {'‚úÖ' if validation_result['template_available'] else '‚ùå'}")

    if validation_result['issues']:
        logger.info(f"\n‚ö†Ô∏è  Issues found:")
        for issue in validation_result['issues']:
            logger.info(f"   ‚Ä¢ {issue}")

    # Validate template if provided
    if template_path:
        template_info = generator.get_template_info(template_path)
        logger.info(f"\nüìÑ Template: {'‚úÖ' if template_info['valid'] else '‚ùå'}")
        if template_info['valid']:
            logger.info(f"   Name: {template_info['name']}")
            logger.info(f"   Type: {template_info['type']}")
            logger.info(f"   Fields: {len(template_info['required_fields'])}")

    # Show available providers
    providers = generator.get_available_providers()
    logger.info(f"\nüîå Available Providers:")
    for p in providers:
        status = "‚úÖ" if p['available'] and p['environment_ready'] else "‚ùå"
        logger.info(f"   {status} {p['name']} ({p['model']})")

    # Exit with appropriate code
    if validation_result['valid']:
        logger.info(f"\n‚úÖ All validations passed - ready for report generation")
        sys.exit(0)
    else:
        logger.info(f"\n‚ùå Validation failed - please resolve issues above")
        sys.exit(2)



def _handle_generation_output(result: dict, verbose: bool) -> None:
    """Handle successful generation output."""
    logger.info("‚úÖ Report generated successfully")

    metadata = result['report_metadata']
    logger.info(f"üìÑ Report Details:")
    logger.info(f"   ‚Ä¢ Output: {result['output_path']}")
    logger.info(f"   ‚Ä¢ Word count: {metadata['word_count']:,}")
    logger.info(f"   ‚Ä¢ Generation time: {result['generation_time_seconds']:.1f}s")
    logger.info(f"   ‚Ä¢ Status: {metadata['validation_status']}")

    if metadata['warnings']:
        logger.info(f"‚ö†Ô∏è  Warnings ({len(metadata['warnings'])}):")
        for warning in metadata['warnings']:
            logger.info(f"   ‚Ä¢ {warning}")

    if verbose:
        provider_info = result['provider_metadata']
        template_info = result['template_metadata']

        logger.info(f"\nüîß Provider Details:")
        logger.info(f"   ‚Ä¢ Provider: {provider_info['provider_name']}")
        logger.info(f"   ‚Ä¢ Model: {provider_info['model_name']}")
        logger.info(f"   ‚Ä¢ Response time: {provider_info['response_time_seconds']:.1f}s")

        logger.info(f"\nüìã Template Details:")
        logger.info(f"   ‚Ä¢ Template: {template_info['template_name']}")
        logger.info(f"   ‚Ä¢ Type: {template_info['template_type']}")
        logger.info(f"   ‚Ä¢ Path: {template_info['file_path']}")


def _print_setup_help(provider: str) -> None:
    """Print setup help for the specified provider."""
    help_text = {
        'gemini': """
üí° Gemini Setup Help:
   1. Install Gemini CLI: https://ai.google.dev/gemini-api/docs/quickstart
   2. Set environment variable: export GEMINI_API_KEY=your_api_key
   3. Verify installation: gemini --version
        """,
        'openai': """
üí° OpenAI Setup Help:
   1. Install OpenAI CLI: pip install openai
   2. Set environment variable: export OPENAI_API_KEY=your_api_key
   3. Verify installation: openai --version
        """,
        'claude': """
üí° Claude Setup Help:
   1. Install Claude CLI: pip install anthropic
   2. Set environment variable: export ANTHROPIC_API_KEY=your_api_key
   3. Verify installation: claude --version
        """
    }

    logger.info(help_text.get(provider, "No setup help available for this provider"))


def _print_provider_help(provider: str) -> None:
    """Print provider-specific troubleshooting help."""
    logger.info(f"\nüîß Troubleshooting {provider}:")
    logger.info("   ‚Ä¢ Check API key is set correctly")
    logger.info("   ‚Ä¢ Verify CLI tool is installed and in PATH")
    logger.info("   ‚Ä¢ Check network connectivity")
    logger.info("   ‚Ä¢ Try increasing timeout with --timeout option")
    logger.info("   ‚Ä¢ Use --validate-only to check configuration")


if __name__ == '__main__':
    main()